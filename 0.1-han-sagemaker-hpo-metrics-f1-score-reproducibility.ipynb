{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-brake",
   "metadata": {},
   "source": [
    "# A Quick Demonstration of SageMaker Reproducibility Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-chosen",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Preparation](#preparation)\n",
    "3. [Download and prepare the data](#download)\n",
    "4. [Train + Hyperparameter tuning](#tune)\n",
    "5. [Deploy](#deploy)\n",
    "6. [Reproducing Objective Value](#wtf)\n",
    "7. [Teardown](#teardown)\n",
    "8. [Training Log](#log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-dictionary",
   "metadata": {},
   "source": [
    "# <a id='introduction'>Introduction</a>\n",
    "\n",
    "We encountered a problem where Sagemaker hyperparameter tuning produced a much higher `f1-score` than other hyperparameter sweep algorithms (`H2OAutoML`, `Scikit-Optimize Bayes`, `RandomizedSearchCV`) that we have tried and our own hand-tuned models. We got excited and decide to pull the model and verify if that `f1-score` displayed was real. Our manual verification using the best model and the same validation data produced an `f1-score` that is muchlower than what's displayed on Sagemaker Hyperparameter Tuning dashboard.\n",
    "\n",
    "This notebook demonstrates the misalignment between the displayed Objective Metrics Value on Hyperparameter Tuning dashboard vs the manually produced objective metrics value using the same model and same dataset.\n",
    "\n",
    "We will use SageMaker Python SDK, a high level SDK, to simplify the way we interact with SageMaker Hyperparameter Tuning.\n",
    "\n",
    "Example adopted from [HPO XGBoost Random Log Notebook](https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/xgboost_random_log/hpo_xgboost_random_log.ipynb), modified to support `SageMaker 2.25.2.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-pathology",
   "metadata": {},
   "source": [
    "# <a id='preparation'>Preparation</a>\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "    The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as SageMaker training.\n",
    "    The IAM role used to give training access to your data. See SageMaker documentation for how to create these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neither-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import xgboost\n",
    "\n",
    "region = boto3.Session().region_name    \n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()                     \n",
    "prefix = 'sagemaker/DEMO-hpo-xgboost-dm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-person",
   "metadata": {},
   "source": [
    "# <a id='download'>Download and prepare the data</a>\n",
    "\n",
    "Here we download the [direct marketing dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing) from UCI's ML Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-24 20:37:53--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘bank-additional.zip’ not modified on server. Omitting download.\n",
      "\n",
      "Archive:  bank-additional.zip\n",
      "  inflating: bank-additional/.DS_Store  \n",
      "  inflating: __MACOSX/bank-additional/._.DS_Store  \n",
      "  inflating: bank-additional/.Rhistory  \n",
      "  inflating: bank-additional/bank-additional-full.csv  \n",
      "  inflating: bank-additional/bank-additional-names.txt  \n",
      "  inflating: bank-additional/bank-additional.csv  \n",
      "  inflating: __MACOSX/._bank-additional  \n"
     ]
    }
   ],
   "source": [
    "!wget -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "!unzip -o bank-additional.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-admission",
   "metadata": {},
   "source": [
    "Now let us load the data, apply some preprocessing, and upload the processed data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "increased-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('./bank-additional/bank-additional-full.csv', sep=';')\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 50)         # Keep the output on one page\n",
    "\n",
    "# Apply some feature processing\n",
    "data['no_previous_contact'] = np.where(data['pdays'] == 999, 1, 0)                                 # Indicator variable to capture when pdays takes a value of 999\n",
    "data['not_working'] = np.where(np.in1d(data['job'], ['student', 'retired', 'unemployed']), 1, 0)   # Indicator for individuals not actively employed\n",
    "model_data = pd.get_dummies(data)                                                                  # Convert categorical variables to sets of indicators\n",
    "\n",
    "# columns that should not be included in the input\n",
    "model_data = model_data.drop(['duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'], axis=1)\n",
    "\n",
    "# split data\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9*len(model_data))])  \n",
    "\n",
    "# save preprocessed file to s3\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "pd.concat([validation_data['y_yes'], validation_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-coordinate",
   "metadata": {},
   "source": [
    "# <a id='tune'>Setup hyperparameter tuning</a>\n",
    "\n",
    "In this example, we are using SageMaker Python SDK to set up and manage the hyperparameter tuning job. We first configure the training jobs the hyperparameter tuning job will launch by initiating an estimator, and define the static hyperparameter and objective.\n",
    "\n",
    "The objective metrics we use is `validation:auc`, which we presume to be `auc` for `validation` data set.  We will only train for one iteration for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cross-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated in sagemaker v2.\n",
    "# s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "# s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train/train.csv'.format(bucket, prefix), content_type='text/csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/validation.csv'.format(bucket, prefix), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rough-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=boto3.Session().region_name,\n",
    "    version='1.2-1',\n",
    "    py_version='py3')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.4xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    eval_metric='f1',\n",
    "    objective='binary:logistic',\n",
    "    num_round=1,\n",
    "#     rate_drop=0.3,\n",
    "#     tweedie_variance_power=1.4\n",
    ")\n",
    "\n",
    "objective_metric_name = 'validation:f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smart-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    'lambda': ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "breeding-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................!\n"
     ]
    }
   ],
   "source": [
    "tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize'\n",
    ")\n",
    "\n",
    "tuner_log.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-burning",
   "metadata": {},
   "source": [
    "Check if jobs have finished and get the logs of the job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serious-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "refined-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>lambda</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>scaling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787034</td>\n",
       "      <td>0.428942</td>\n",
       "      <td>sagemaker-xgboost-210324-2037-001-0c35a89d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.23828</td>\n",
       "      <td>2021-03-24 20:40:12+00:00</td>\n",
       "      <td>2021-03-24 20:41:06+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha    lambda                             TrainingJobName  \\\n",
       "0  0.787034  0.428942  sagemaker-xgboost-210324-2037-001-0c35a89d   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed              0.23828 2021-03-24 20:40:12+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds scaling  \n",
       "0 2021-03-24 20:41:06+00:00                        54.0     log  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_log = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "\n",
    "assert status_log == 'Completed', \"First must be completed, was {}\".format(status_log)\n",
    "\n",
    "df_log = sagemaker.HyperparameterTuningJobAnalytics(tuner_log.latest_tuning_job.job_name).dataframe()\n",
    "df_log['scaling'] = 'log'\n",
    "final_objective_value = df_log['FinalObjectiveValue'][0]\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-mercury",
   "metadata": {},
   "source": [
    "# <a id='deploy'>Deploy</a>\n",
    "\n",
    "After the model's trained, we will deploy it using Sagemaker to keep AWS happy and our wallets empty.\n",
    "\n",
    "[Reference deployment code is here.](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "preceding-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-24 20:41:06 Starting - Preparing the instances for training\n",
      "2021-03-24 20:41:06 Downloading - Downloading input data\n",
      "2021-03-24 20:41:06 Training - Training image download completed. Training in progress.\n",
      "2021-03-24 20:41:06 Uploading - Uploading generated training model\n",
      "2021-03-24 20:41:06 Completed - Training job completed\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = tuner_log.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-discussion",
   "metadata": {},
   "source": [
    "# <a id='wtf'> Reproducing Objective Value</a>\n",
    "\n",
    "For this tuning job, we set our `objective_metric_name` as `validation:auc` and the tuner found the `FinalObjectiveValue` of `0.75241`.\n",
    "\n",
    "Awesomesauce. Let's try to reproduce the same `FinalObjectiveValue` by running our validation data through the trained model and [calculate the auc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html) using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "million-representation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproduced validation:f1 is 0.2758. Advertised FinalObjectiveValue is 0.2383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_data_array = validation_data.drop(['y_no', 'y_yes'], axis=1).values               # load the data into an array\n",
    "xgb_predictor.serializer = CSVSerializer()                                                   # set the serializer type\n",
    "predictions = xgb_predictor.predict(validation_data_array).decode('utf-8')                   # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',')                                  # and turn the prediction into an array\n",
    "predictions_array = np.where(predictions_array > 0.5, 1, 0)                                  # sklearn f1-score takes labels, not class probabilities\n",
    "\n",
    "validation_f1 = metrics.f1_score(validation_data['y_yes'], predictions_array)\n",
    "print(f'Reproduced validation:f1 is {validation_f1:.4}. Advertised FinalObjectiveValue is {final_objective_value:.4}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-glenn",
   "metadata": {},
   "source": [
    "Hmm, what's going on?  Maybe the FinalObjectiveValue is auc calculated on the training set? Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproduced train:f1 is 0.3463. Advertised FinalObjectiveValue is 0.2383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_array = train_data.drop(['y_no', 'y_yes'], axis=1).values                          # load the data into an array\n",
    "xgb_predictor.serializer = CSVSerializer()                                                    # set the serializer type\n",
    "predictions = xgb_predictor.predict(train_data_array).decode('utf-8')                         # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',')                                   # and turn the prediction into an array\n",
    "predictions_array = np.where(predictions_array > 0.5, 1, 0)                                   # sklearn f1-score takes labels, not class probabilities\n",
    "\n",
    "train_f1 = metrics.f1_score(train_data['y_yes'], predictions_array)\n",
    "print(f'Reproduced train:f1 is {train_f1:.4}. Advertised FinalObjectiveValue is {final_objective_value:.4}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-atlanta",
   "metadata": {},
   "source": [
    "`FinalObjectiveValue` is expected to be `validation:f1`. However, it neither equals to `validation:f1` or `train:f1`. So, what does that number represent? On Sagemaker Hyperparameter Tuner, we did specify it `eval_metric` to `f1` and `objective_metric_name` to `validation:f1`.\n",
    "\n",
    "For sanity Check, we will try to download the model to local and use the local model to make inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hungarian-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = df_log['TrainingJobName'][0]\n",
    "# model_file = f's3://{bucket}/{prefix}/output/{training_job_name}/output/model.tar.gz'  \n",
    "all_prefix = f\"{prefix}/output/{df_log['TrainingJobName'][0]}/output/\"\n",
    "filename = \"model.tar.gz\"\n",
    "\n",
    "# No idea why boto3 client API cant access the file\n",
    "# s3 = boto3.client('s3')\n",
    "# s3.download_file(Bucket=bucket, Key=all_prefix, Filename=filename)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(all_prefix+filename, \"model.tar.gz\")\n",
    "\n",
    "tar = tarfile.open('model.tar.gz', \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "xgb_model = pickle.load(open(\"xgboost-model\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laden-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score displayed in FinalObjectiveValue is: 0.23827999830245972\n",
      "f1-score using loaded model on validation data is: 0.27580511973575556\n"
     ]
    }
   ],
   "source": [
    "validation_data_dmatrix = xgboost.DMatrix(validation_data_array)\n",
    "y_predict_proba = xgb_model.predict(validation_data_dmatrix)\n",
    "y_pred_ = np.where(y_predict_proba > 0.5, 1, 0)\n",
    "\n",
    "print(f\"f1-score displayed in FinalObjectiveValue is: {df_log['FinalObjectiveValue'][0]}\")\n",
    "print(f\"f1-score using loaded model on validation data is: {metrics.f1_score(validation_data['y_yes'], y_pred_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-caribbean",
   "metadata": {},
   "source": [
    "Good news: downloaded model produces the same f1-score on validation data compare to the deployed model.\n",
    "\n",
    "Bad news: it is still different than the advertised FinalObjectiveValue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-edwards",
   "metadata": {},
   "source": [
    "# <a id='teardown'>Teardown</a>\n",
    "\n",
    "Teardown the deployed endpoint and the model so we can afford food tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()\n",
    "xgb_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-percentage",
   "metadata": {},
   "source": [
    "# <a id='Log'>Training Job Cloudwatch Log</a>\n",
    "\n",
    "```\n",
    "\tNo older events at this moment. \n",
    "Retry\n",
    "\t2021-03-24T13:40:57.660-07:00\t[2021-03-24 20:40:55.364 ip-10-0-184-77.us-east-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value f1 to Json.\n",
    "\t2021-03-24T13:40:57.661-07:00\tReturning the value itself\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:f1 to Json.\n",
    "\t2021-03-24T13:40:57.661-07:00\tReturning the value itself\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\n",
    "\t2021-03-24T13:40:57.661-07:00\tReturning the value itself\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Determined delimiter of CSV input is ','\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Determined delimiter of CSV input is ','\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Determined delimiter of CSV input is ','\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Determined delimiter of CSV input is ','\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Single node training.\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Setting up HPO optimized metric to be : f1\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Train matrix has 28831 rows\n",
    "\t2021-03-24T13:40:57.661-07:00\tINFO:root:Validation matrix has 8238 rows\n",
    "\t2021-03-24T13:40:57.661-07:00\t[20:40:55] WARNING: ../src/learner.cc:516:\n",
    "\t2021-03-24T13:40:57.661-07:00\tParameters: { _tuning_objective_metric } might not be used. This may not be accurate due to some parameters are only used in language bindings but passed down to XGBoost core. Or some parameters are not used but slip through this verification. Please open an issue if you find above cases.\n",
    "\t2021-03-24T13:40:57.661-07:00\t[0]#011train-error:0.09705#011validation-error:0.10646#011train-f1:0.23900#011validation-f1:0.23828\n",
    "\t\tNo newer events at this moment. Auto retry paused. \n",
    "Resume\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "played-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (ef-datascience)",
   "language": "python",
   "name": "ef-datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
